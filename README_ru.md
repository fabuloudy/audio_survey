# Deep Learning Survey for Audio Data

[—Ä—É—Å—Å–∫–∏–π](README_ru.md)

## –†–µ–∑—é–º–µ

–û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ ESC50, —Å –≥–∏–±–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ –º–µ–ª —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞—Ö –∏ 2d —Å–≤—ë—Ä—Ç–∫–∞—Ö. [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](logs/results/esc50/)

## –î–∞—Ç–∞—Å–µ—Ç—ã

#### ESC-50

[![kaggle](https://www.kaggle.com/static/images/favicon.ico)](https://www.kaggle.com/datasets/ludovick/esc50dataset) [![paperswithcode](https://paperswithcode.com/favicon.ico)](https://paperswithcode.com/dataset/esc-50) [![github](https://github.githubassets.com/favicons/favicon-dark.svg)](https://github.com/karolpiczak/ESC-50)

ESC-50 –¥–∞—Ç–∞—Å–µ—Ç —Å **2000** –ø—Ä–∏—Ä–æ–¥–Ω—ã–º–∏ –∞—É–¥–∏–æ –∑–∞–ø–∏—Å—è–º–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ –∞—É–¥–∏–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.

–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ **5**-—Å–µ–∫—É–Ω–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –≤ **50** –∫–ª–∞—Å—Å–æ–≤ (**40**  –∞–¥—É–∏–æ –Ω–∞ –∫–ª–∞—Å—Å) —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ 5 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π: `Animals`, `Natural soundscapes & water sounds`, `Human non-speech sounds`, `Interior/domestic sounds`, `Exterior/urban noises`

#### UrbanSound8K

[![kaggle](https://www.kaggle.com/static/images/favicon.ico)](https://www.kaggle.com/datasets/chrisfilo/urbansound8k) [![paperswithcode](https://paperswithcode.com/favicon.ico)](https://paperswithcode.com/dataset/urbansound8k-1)

–†–∞–∑–º–µ—á–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å **8732** –ø—Ä–∏—Ä–æ–¥–Ω—ã–º–∏ –∞—É–¥–∏–æ –∑–∞–ø–∏—è—Å–º–∏ (–¥–æ **4** —Å–µ–∫—É–¥) —Å **10** –∫–ª–∞—Å—Å–∞–º–∏: `air_conditioner`, `car_horn`, `children_playing`, `dog_bark`, `drilling`, `enginge_idling`, `gun_shot`, `jackhammer`, `siren` and `street_music`

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ üî®

–°–∫–∞—á–∞—Ç—å ESC50 –¥–∞—Ç–∞—Å–µ—Ç, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ UrbanSound8k

–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥–∏ `config.yaml`

```
pip install requirements.txt
```

```
python preproccesing.py
```

```
python train.py
```

## My specs

RAM: 16GB
GPU: 1660super 6GB
CPU: i5-11400F

## Config

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π: `gelu`, `relu`, `lrelu` (LeakyReLU), `swiglu` [4]   

sample_rate (int) - —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞  

mel_spectrogram - —Å–ª–æ–≤–∞—Ä—å —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è *torchaudio.transforms.MelSpectrogram* –∫–ª–∞—Å—Å–∞. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: *[1] 3.1. Feature Extraction*. –ø—Ä–æ –º–µ–ª —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å –∑–¥–µ—Å—å [habr](https://habr.com/ru/post/462527/) –∏–ª–∏ –∑–¥–µ—Å—å
* win_length - –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö, –≤—ã—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
* hop_length - –†–∞–∑–º–µ—Ä —à–∞–≥–∞ –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö, –≤—ã—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
* n_mels - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ–ª-—Ñ–∏–ª—å—Ç—Ä–æ–≤
* f_min - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
* f_max - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞

augmentation - –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏–º–µ–Ω—è—è –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º —Ä–∞–∑–Ω–æ–≥–æ —Ä–æ–¥–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è. –ö–∞–∂–¥–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–º–µ–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä `p` - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∏—è —ç—Ç–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ –≤–∑—è—Ç–æ–≥–æ —Å–µ–º–ø–ª–∞/–±–∞—Ç—á–∞. –£–∫–∞–∂–∏—Ç–∏ p=0 –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ß–∞—Å—Ç—å –∫–æ–¥–∞ –≤–∑—è—Ç–∞ –∏–∑: *[3] 3.2. Data Augmentation*.
* reverb: —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏—è, –Ω–µ —Å—Ç–æ–∏—Ç –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –∫—Ä–∞–π–Ω–µ –º–µ–¥–ª–µ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è —Å–≤—ë—Ä—Ç–∫–∏
  * p (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –±–∞—Ç—á
* time_shift: —Å–ª—É—á–∞–π–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∞—É–¥–∏–æ –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏ –∏ —Å—É–ª—á–∞–π–Ω–æ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç/—Å–∂–∏–º–∞–µ—Ç –∫–∞–∂–¥—É—é
  * p (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
* noise: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —à—É–º –∫ —Å–∏–≥–Ω–∞–ª—É
  * p (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
  * min_snr_db (float) - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —à—É–º–∞ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Å–∏–≥–Ω–∞–ª—É
  * max_snr_db (float) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —à—É–º–∞ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Å–∏–≥–Ω–∞–ª—É
* dropblock: –∑–∞–Ω—É–ª—è–µ—Ç –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã) *[6] - DropBlock: A regularization method for convolutional networks*
  * p  (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –±–∞—Ç—á
  * dp (float) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –≤ %, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ `p` –≤ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º `Dropout`
  * block_size:
    * t (int) - —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –≤–¥–æ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å–∏
    * f (int) - —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –≤–¥–æ–ª—å —á–∞—Å—Ç–æ—Ç–Ω–æ–π –æ—Å–∏
* time_masking: –º–∞—Å–∫–∏—Ä—É–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ –æ—Å–∏ –≤—Ä–µ–º–µ–Ω–∏
  * p (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
  * tmp (int) - `time_mask_param`, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –º–∞—Å–∫–∏.
  * num (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
* freq_masking: –º–∞—Å–∫–∏—Ä—É–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ–π –æ—Å–∏
  * p (float) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
  * fmp (int) - `freq_mask_param`, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –º–∞—Å–∫–∏.
  * num (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫

pretrain_urban (bool) - –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ urbansound  

pretrain - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è
* num_workers (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö. 0 –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ. –ù–µ —Ä–µ–∫—É–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–æ–ª—å—à–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —è–¥–µ—Ä –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ 
* epochs (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö. –ï—Å–ª–∏ 0 –∏ `patience` > 0 –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –ø–æ–∫–∞ 
* lr (float) - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
* weight_decay (float) - weight decay –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç [10]
* batch_size (int) - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
* accum_iter (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ gradient accumulation. –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ  [7]
* grad_clip_value (float) - –∑–Ω–∞—á–µ–Ω–∏–µ gradient clipping norm [8]
* grad_clip_norm (float) - –∑–Ω–∞—á–µ–Ω–∏–µ gradient clipping [8]
* use_checkpoint (bool) - gradient checkpoint. –Ω–µ —Å—Ç–æ–∏—Ç —ç—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [9]

train - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –Ω–∞ ESC50, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ pretrain  

model - –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏. –í—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: (B, C, T, F) –≥–¥–µ B - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, T - –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–ª–∏–Ω—ã –∞—É–¥–∏–æ), F - —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –º–µ–ª —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã 
* res_block - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã—Ö-–æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤, —Å 3 –∫–æ–Ω–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏ –∏ 2 –±–∞—Ç—á –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è–º–∏.
  * activation (str) - —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –º–µ–∂–¥—É –∫–æ–Ω–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏
  * batch_first (bool) - –ø—Ä–∏–º–µ–Ω—è–µ—Ç –±–∞—Ç—á –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ—Å–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –µ—Å–ª–∏ `true` –∏ –ø–µ—Ä–µ–¥ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –µ—Å–ª–∏ `false`
  * kernel_size (list[int, int]) - —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ –¥–≤—É—Ö –æ—Å–Ω–æ–≤—ã–Ω—Ö —Å–≤—ë—Ä—Ç–æ–∫
  * kernel_size_res (list[int, int]) - —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ –æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–≤—ë—Ä—Ç–∫–∏
* blocks (dictionary[str, list|int|float]) - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏. –°–ø–∏—Å–æ–∫ —Å –±–ª–æ–∫–∞–º–∏ –∏ —Å–ª–æ—è–º–∏. –î–æ—Å—Ç—É–ø–Ω—ã–µ –±–ª–æ–∫–∏ –∏ —Å–ª–æ–∏:
  * res (list[int, int]) - –∫–æ–Ω–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ-–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –±–ª–æ–∫, —Å–ø–∏—Å–æ–∫ —Å –¥–≤—É–º—è –∑–Ω–∞—á–µ–Ω–∏—è–º–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–µ—Ä–≤–æ–≥–æ –∫–æ–Ω–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–ª–æ—è –∏ –≤—Ç–æ—Ä–æ–≥–æ
  * max_pool (list[int, int]) - —Å–ª–æ–π –ø—É–ª–∏–Ω–≥–∞, —Å–ø–∏—Å–æ–∫ —Å –¥–≤—É–º—è –∑–Ω–∞—á–µ–Ω–∏—è–º–∏: —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ –ø–æ –æ—Å–∏ T (–≤—Å–µ–≥–¥–∞ —Ä–∞–≤–Ω–æ 1 –ø–æ –æ—Å–∏ F) –∏ —à–∞–≥ –ø–æ –æ—Å–∏ T (–≤—Å–µ–≥–¥–∞ —Ä–∞–≤–Ω–æ 1 –ø–æ –æ—Å–∏ F)
  * activation (str) - —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
  * drop (list[float, float, int, int]) - dropblock —Å–ª–æ–π, —Å–ø–∏—Å–æ–∫ —Å 4 –∑–Ω–∞—á–µ–Ω–∏—è–º–∏: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –±–∞—Ç—á, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –≤ %, —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ T, —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ F
  * dropout (float) - –∫–æ—ç—Ñ–∏—Ü–∏–µ–Ω—Ç dropout2d
  * fc (int) - –õ–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤
  * pooling - —Å–ª–æ–π –ø—É–ª–∏–Ω–≥–∞
    * mode (str) - –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã –ø—É–ª–∏–Ω–≥–∞:
      * avg - average pooling
      * max - max pooling
      * sum - sum of avg and max pooling
      * mul - mul of avg and max pooling
    * flat (bool) - —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤–µ–∫—Ç–æ—Ä –ø–æ –æ—Å–∏ C –∏ F. –ù–∞ –≤—Ö–æ–¥–µ (B, C, T, F) –Ω–∞ –≤—ã—Ö–æ–¥–µ (B, T, F*C)

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏

1. ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern Recognition. *Sergey Verbitskiy*, *Vladimir Berikov*, *Viacheslav Vyshegorodtsev*. [arxiv abs](https://arxiv.org/abs/2106.01621v7)
2. PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition. *Qiuqiang Kong*, *Yin Cao*, *Turab Iqbal*, *Yuxuan Wang*, *Wenwu Wang*, *Mark D. Plumbley*. [arxiv abs](https://arxiv.org/abs/1912.10211)
3. End-to-End Audio Strikes Back: Boosting Augmentations Towards An Efficient Audio Classification Network. *Avi Gazneli*, *Gadi Zimerman*, *Tal Ridnik*, *Gilad Sharir*, *Asaf Noy*. [arxiv abs](https://arxiv.org/abs/2204.11479)
4. GLU Variants Improve Transformer. *Noam Shazeer*. [arxiv abs](https://arxiv.org/abs/2002.05202v1)
5. When Does Label Smoothing Help? *Rafael M√ºller*, *Simon Kornblith*, *Geoffrey Hinton*. [arxiv abs](https://arxiv.org/abs/1906.02629)
6. DropBlock: A regularization method for convolutional networks. *Golnaz Ghiasi*, *Tsung-Yi Lin*, *Quoc V. Le*. [arxiv abs](https://arxiv.org/abs/1810.12890v1)
7. What is Gradient Accumulation in Deep Learning? [towardsdatascience](https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa)
8. Gradient Clipping. [paperswithcode](https://paperswithcode.com/method/gradient-clipping)
9. Gradient Checkpointing. [paperswithcode](https://paperswithcode.com/method/gradient-checkpointing)
10. Understanding and Scheduling Weight Decay. *Zeke Xie*, *Issei Sato*, *Masashi Sugiyama*.[arxiv abs](https://arxiv.org/abs/2011.11152)